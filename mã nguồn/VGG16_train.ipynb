{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxDlACBKREu9"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/linhtinh/best_model.hdf5')"
      ],
      "metadata": {
        "id": "-vEBkr9lxiF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yvjYE8Uxq7L",
        "outputId": "85606f68-afba-4c16-b639-ad16a96e94f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 21)                526869    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,241,557\n",
            "Trainable params: 526,869\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZtvAtOCmJKVh",
        "outputId": "82c25d59-8a9d-4e7a-8f69-f1083588cf85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zqi8O9deSRtM"
      },
      "outputs": [],
      "source": [
        "train_data_dir = '/content/drive/MyDrive/Public folder/Data/Train'\n",
        "validation_data_dir = '/content/drive/MyDrive/Public folder/Data/Test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGc4jo2Qa082"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = [224, 224]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrDLiaR2dZIZ",
        "outputId": "7f773c36-2190-416a-b5eb-13e6627a800e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztl3gLcYddED"
      },
      "outputs": [],
      "source": [
        "for layer in vgg.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-0Jnta7deli"
      },
      "outputs": [],
      "source": [
        "folders = glob('/content/drive/MyDrive/Public folder/Data/Train/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmBHCuqHfYNo",
        "outputId": "806ecfaa-1ffe-4cff-a774-f9a87c927822"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Public folder/Data/Train/Thu cung',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Tai lieu',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Toa nha',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Selfie',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Nguoi',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Xe co',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Song suoi ho',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Giay',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Hoa don',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Hoa',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Dien thoai',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Chup man hinh',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Bien',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Bau troi',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Bia sach',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Dong ruong',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Cay coi',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Do an',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Duong pho',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Doi nui',\n",
              " '/content/drive/MyDrive/Public folder/Data/Train/Ao quan']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXQ9zRnNdjgT"
      },
      "outputs": [],
      "source": [
        "# our layers - you can add more if you want\n",
        "x = Flatten()(vgg.output)\n",
        "# x = Dense(1000, activation='relu')(x)\n",
        "prediction = Dense(len(folders), activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qD9rjoEAdnVZ"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=vgg.input, outputs=prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbK11irgdpbs",
        "outputId": "095eb587-6b69-4f0d-ae3a-9cc9c127de43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 21)                526869    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,241,557\n",
            "Trainable params: 526,869\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSndX8UedtPC"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tyHxSG7dwhj",
        "outputId": "8602f4ce-a633-440b-8a77-7644bd91c4c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 11598 images belonging to 21 classes.\n",
            "Found 1050 images belonging to 21 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(validation_data_dir,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/linhtinh/best_model.hdf5\", monitor='loss', verbose=1,\n",
        "    save_best_only=True, mode='auto', save_freq=5)"
      ],
      "metadata": {
        "id": "uXDsA_dKq2E3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7FdVd2ve9PJ",
        "outputId": "c544ace7-6ec6-4b9b-9f62-61183d8b39b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  4/363 [..............................] - ETA: 1:50:28 - loss: 0.1566 - accuracy: 0.9688\n",
            "Epoch 00001: loss improved from inf to 0.12981, saving model to /content/drive/MyDrive/linhtinh/best_model.hdf5\n",
            "  9/363 [..............................] - ETA: 1:43:03 - loss: 0.1573 - accuracy: 0.9653\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            " 14/363 [>.............................] - ETA: 1:39:10 - loss: 0.1563 - accuracy: 0.9554\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            " 19/363 [>.............................] - ETA: 1:36:34 - loss: 0.1418 - accuracy: 0.9589\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            " 24/363 [>.............................] - ETA: 1:35:53 - loss: 0.1450 - accuracy: 0.9570\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            " 29/363 [=>............................] - ETA: 1:33:58 - loss: 0.1331 - accuracy: 0.9580\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            " 34/363 [=>............................] - ETA: 1:32:23 - loss: 0.1277 - accuracy: 0.9568\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            " 39/363 [==>...........................] - ETA: 1:30:42 - loss: 0.1368 - accuracy: 0.9567\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            " 44/363 [==>...........................] - ETA: 1:29:43 - loss: 0.1343 - accuracy: 0.9574\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            " 49/363 [===>..........................] - ETA: 1:28:15 - loss: 0.1283 - accuracy: 0.9579\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            " 54/363 [===>..........................] - ETA: 1:26:50 - loss: 0.1378 - accuracy: 0.9572\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            " 59/363 [===>..........................] - ETA: 1:25:10 - loss: 0.1426 - accuracy: 0.9566\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            " 64/363 [====>.........................] - ETA: 1:23:37 - loss: 0.1470 - accuracy: 0.9556\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            " 69/363 [====>.........................] - ETA: 1:22:11 - loss: 0.1442 - accuracy: 0.9570\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            " 74/363 [=====>........................] - ETA: 1:20:46 - loss: 0.1394 - accuracy: 0.9573\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            " 79/363 [=====>........................] - ETA: 1:19:35 - loss: 0.1371 - accuracy: 0.9577\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            " 84/363 [=====>........................] - ETA: 1:17:36 - loss: 0.1356 - accuracy: 0.9584\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            " 89/363 [======>.......................] - ETA: 1:16:13 - loss: 0.1375 - accuracy: 0.9572\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            " 94/363 [======>.......................] - ETA: 1:14:52 - loss: 0.1420 - accuracy: 0.9555\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            " 99/363 [=======>......................] - ETA: 1:13:26 - loss: 0.1430 - accuracy: 0.9562\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "104/363 [=======>......................] - ETA: 1:12:07 - loss: 0.1431 - accuracy: 0.9559\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "109/363 [========>.....................] - ETA: 1:10:43 - loss: 0.1421 - accuracy: 0.9559\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "114/363 [========>.....................] - ETA: 1:09:30 - loss: 0.1406 - accuracy: 0.9562\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "119/363 [========>.....................] - ETA: 1:08:06 - loss: 0.1372 - accuracy: 0.9567\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "124/363 [=========>....................] - ETA: 1:06:42 - loss: 0.1370 - accuracy: 0.9565\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "129/363 [=========>....................] - ETA: 1:05:18 - loss: 0.1345 - accuracy: 0.9572\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "134/363 [==========>...................] - ETA: 1:03:53 - loss: 0.1350 - accuracy: 0.9574\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "139/363 [==========>...................] - ETA: 1:02:30 - loss: 0.1343 - accuracy: 0.9571\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "144/363 [==========>...................] - ETA: 1:01:08 - loss: 0.1334 - accuracy: 0.9573\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "149/363 [===========>..................] - ETA: 59:44 - loss: 0.1342 - accuracy: 0.9575  \n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "154/363 [===========>..................] - ETA: 58:28 - loss: 0.1319 - accuracy: 0.9582\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "159/363 [============>.................] - ETA: 57:06 - loss: 0.1402 - accuracy: 0.9562\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "164/363 [============>.................] - ETA: 55:42 - loss: 0.1402 - accuracy: 0.9560\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "169/363 [============>.................] - ETA: 54:18 - loss: 0.1416 - accuracy: 0.9557\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "174/363 [=============>................] - ETA: 52:53 - loss: 0.1395 - accuracy: 0.9562\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "179/363 [=============>................] - ETA: 51:30 - loss: 0.1399 - accuracy: 0.9564\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "184/363 [==============>...............] - ETA: 50:07 - loss: 0.1402 - accuracy: 0.9562\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "189/363 [==============>...............] - ETA: 48:48 - loss: 0.1416 - accuracy: 0.9564\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "194/363 [===============>..............] - ETA: 47:24 - loss: 0.1419 - accuracy: 0.9567\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "199/363 [===============>..............] - ETA: 46:00 - loss: 0.1413 - accuracy: 0.9569\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "204/363 [===============>..............] - ETA: 44:36 - loss: 0.1419 - accuracy: 0.9568\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "209/363 [================>.............] - ETA: 43:12 - loss: 0.1436 - accuracy: 0.9562\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "214/363 [================>.............] - ETA: 41:48 - loss: 0.1434 - accuracy: 0.9565\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "219/363 [=================>............] - ETA: 40:24 - loss: 0.1426 - accuracy: 0.9562\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "224/363 [=================>............] - ETA: 39:03 - loss: 0.1416 - accuracy: 0.9565\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "229/363 [=================>............] - ETA: 37:38 - loss: 0.1432 - accuracy: 0.9564\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "234/363 [==================>...........] - ETA: 36:16 - loss: 0.1441 - accuracy: 0.9565\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "239/363 [==================>...........] - ETA: 34:51 - loss: 0.1439 - accuracy: 0.9567\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "244/363 [===================>..........] - ETA: 33:27 - loss: 0.1443 - accuracy: 0.9561\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "249/363 [===================>..........] - ETA: 32:02 - loss: 0.1439 - accuracy: 0.9564\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "254/363 [===================>..........] - ETA: 30:37 - loss: 0.1447 - accuracy: 0.9562\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "259/363 [====================>.........] - ETA: 29:14 - loss: 0.1469 - accuracy: 0.9561\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "264/363 [====================>.........] - ETA: 27:49 - loss: 0.1462 - accuracy: 0.9561\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "269/363 [=====================>........] - ETA: 26:24 - loss: 0.1489 - accuracy: 0.9554\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "274/363 [=====================>........] - ETA: 24:59 - loss: 0.1484 - accuracy: 0.9554\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "279/363 [======================>.......] - ETA: 23:35 - loss: 0.1508 - accuracy: 0.9548\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "284/363 [======================>.......] - ETA: 22:10 - loss: 0.1515 - accuracy: 0.9542\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "289/363 [======================>.......] - ETA: 20:45 - loss: 0.1526 - accuracy: 0.9540\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "294/363 [=======================>......] - ETA: 19:23 - loss: 0.1543 - accuracy: 0.9537\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "299/363 [=======================>......] - ETA: 17:58 - loss: 0.1546 - accuracy: 0.9535\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "304/363 [========================>.....] - ETA: 16:34 - loss: 0.1548 - accuracy: 0.9538\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "309/363 [========================>.....] - ETA: 15:09 - loss: 0.1557 - accuracy: 0.9531\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "314/363 [========================>.....] - ETA: 13:45 - loss: 0.1550 - accuracy: 0.9533\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "319/363 [=========================>....] - ETA: 12:21 - loss: 0.1559 - accuracy: 0.9530\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "324/363 [=========================>....] - ETA: 10:56 - loss: 0.1615 - accuracy: 0.9522\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "329/363 [==========================>...] - ETA: 9:32 - loss: 0.1615 - accuracy: 0.9520\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "334/363 [==========================>...] - ETA: 8:08 - loss: 0.1617 - accuracy: 0.9518\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "339/363 [===========================>..] - ETA: 6:44 - loss: 0.1629 - accuracy: 0.9517\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "344/363 [===========================>..] - ETA: 5:19 - loss: 0.1631 - accuracy: 0.9513\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "349/363 [===========================>..] - ETA: 3:55 - loss: 0.1629 - accuracy: 0.9514\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "354/363 [============================>.] - ETA: 2:31 - loss: 0.1644 - accuracy: 0.9509\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "359/363 [============================>.] - ETA: 1:07 - loss: 0.1640 - accuracy: 0.9510\n",
            "Epoch 00001: loss did not improve from 0.12981\n",
            "363/363 [==============================] - 6650s 18s/step - loss: 0.1636 - accuracy: 0.9510 - val_loss: 1.2218 - val_accuracy: 0.7971\n",
            "CPU times: user 3h 31min 37s, sys: 1min 54s, total: 3h 33min 32s\n",
            "Wall time: 1h 50min 53s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "r = model.fit(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=1,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set),\n",
        "  callbacks=[checkpoint]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/linhtinh/my_model.h5')"
      ],
      "metadata": {
        "id": "S1kOkoFz8lUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fnsk2d8Ze-SH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "9849cf4b-3104-4ce7-b9e0-4eecb09eb50a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkchT3h9f5Uc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "3f0e2991-b08e-423f-b9db-ceaac11c38f0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(r.history['accuracy'], label='train acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/drive/MyDrive/linhtinh/my_model.h5')"
      ],
      "metadata": {
        "id": "TQ5DMEs4iIEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdV0dOPtQv6V",
        "outputId": "3b322207-27a7-46d2-b174-c5847f62d148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-3.13.0-py3-none-any.whl (77 kB)\n",
            "\u001b[?25l\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 10 kB 17.8 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 20 kB 20.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 30 kB 23.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 40 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 51 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 61 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 71 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: tensorflow<3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.7.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.19.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (12.0.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.10.0.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.23.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.13.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.43.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.4.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.1)\n",
            "Installing collected packages: tensorflowjs\n",
            "Successfully installed tensorflowjs-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflowjs as tfjs\n",
        "\n",
        "tfjs.converters.save_keras_model(model, '/content/drive/MyDrive/linhtinh')"
      ],
      "metadata": {
        "id": "qhP50NZGO9bP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "small_img_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}